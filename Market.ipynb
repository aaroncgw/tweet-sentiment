{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>1133.00</td>\n",
       "      <td>0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>1136.50</td>\n",
       "      <td>-0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>1136.00</td>\n",
       "      <td>0.010343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>1147.75</td>\n",
       "      <td>0.000653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close    return\n",
       "Date                         \n",
       "2012-01-04  1133.00  0.003089\n",
       "2012-01-05  1136.50 -0.002200\n",
       "2012-01-06  1134.00  0.001764\n",
       "2012-01-09  1136.00  0.010343\n",
       "2012-01-10  1147.75  0.000653"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load market data\n",
    "es = pd.read_csv('data/spx.csv')\n",
    "es.Date = pd.to_datetime(es.Date)\n",
    "es.set_index('Date', inplace=True)\n",
    "\n",
    "# Calculate 1 day returns, and roll one day after to use as prediciton\n",
    "es['return'] = np.roll(es['Close'].pct_change(),-1)\n",
    "es = es.loc['2012-01-04':'2020-5-29']\n",
    "es.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_average</th>\n",
       "      <th>daily_average_fintwit</th>\n",
       "      <th>daily_average_news</th>\n",
       "      <th>daily_average_politics</th>\n",
       "      <th>daily_average_trader</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>topic_coherence</th>\n",
       "      <th>topic_coherence_diff</th>\n",
       "      <th>recon_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>-0.266243</td>\n",
       "      <td>-0.334767</td>\n",
       "      <td>-0.166645</td>\n",
       "      <td>-0.239557</td>\n",
       "      <td>-0.336303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744901</td>\n",
       "      <td>0.898953</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>-0.337371</td>\n",
       "      <td>-0.384344</td>\n",
       "      <td>-0.291280</td>\n",
       "      <td>-0.243320</td>\n",
       "      <td>-0.368697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644985</td>\n",
       "      <td>0.845906</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>-0.325877</td>\n",
       "      <td>-0.355626</td>\n",
       "      <td>-0.321614</td>\n",
       "      <td>-0.214214</td>\n",
       "      <td>-0.354338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729873</td>\n",
       "      <td>0.811649</td>\n",
       "      <td>0.005132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>-0.252546</td>\n",
       "      <td>-0.257554</td>\n",
       "      <td>-0.255376</td>\n",
       "      <td>-0.235941</td>\n",
       "      <td>-0.223905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670430</td>\n",
       "      <td>0.847776</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>-0.302168</td>\n",
       "      <td>-0.332257</td>\n",
       "      <td>-0.267115</td>\n",
       "      <td>-0.251730</td>\n",
       "      <td>-0.336150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.686796</td>\n",
       "      <td>0.872777</td>\n",
       "      <td>0.002024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            daily_average  daily_average_fintwit  daily_average_news  \\\n",
       "Date                                                                   \n",
       "2012-01-04      -0.266243              -0.334767           -0.166645   \n",
       "2012-01-05      -0.337371              -0.384344           -0.291280   \n",
       "2012-01-06      -0.325877              -0.355626           -0.321614   \n",
       "2012-01-09      -0.252546              -0.257554           -0.255376   \n",
       "2012-01-10      -0.302168              -0.332257           -0.267115   \n",
       "\n",
       "            daily_average_politics  daily_average_trader  num_tweets  \\\n",
       "Date                                                                   \n",
       "2012-01-04               -0.239557             -0.336303         1.0   \n",
       "2012-01-05               -0.243320             -0.368697         1.0   \n",
       "2012-01-06               -0.214214             -0.354338         1.0   \n",
       "2012-01-09               -0.235941             -0.223905         1.0   \n",
       "2012-01-10               -0.251730             -0.336150         1.0   \n",
       "\n",
       "            topic_coherence  topic_coherence_diff  recon_ratio  \n",
       "Date                                                            \n",
       "2012-01-04         0.744901              0.898953     0.002581  \n",
       "2012-01-05         0.644985              0.845906     0.004651  \n",
       "2012-01-06         0.729873              0.811649     0.005132  \n",
       "2012-01-09         0.670430              0.847776     0.009600  \n",
       "2012-01-10         0.686796              0.872777     0.002024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sentiment and topic features\n",
    "sentiment_features = pd.read_csv('data/sentiment_features.csv')\n",
    "nmf_features = pd.read_csv('data/nmf_features.csv')\n",
    "\n",
    "# Merge features\n",
    "sentiment_features = sentiment_features.iloc[1:].reset_index(drop=True)\n",
    "features = nmf_features.copy()\n",
    "features.Date = pd.to_datetime(features.Date, dayfirst=True)\n",
    "features.set_index('Date', inplace=True)\n",
    "sentiment_features.index = features.index\n",
    "features = sentiment_features.join(features).drop(['Date'],axis=1)\n",
    "features.index = pd.to_datetime(features.index)\n",
    "features.sort_index(inplace=True)\n",
    "\n",
    "#features.drop(['daily_average_politics'],axis=1, inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "Cross validate max_depth for RandomForest and GradientBoostingClassifier  \n",
    "Range of max_depth = 6-20  \n",
    "Exclude low levels of max_depth to avoid the model always choosing same category  \n",
    "Use ROC-AUC and logloss as measure. They yield same rankings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoff for test set\n",
    "date = '2018-12-31'\n",
    "\n",
    "es_class = 1*(es['return'] >0)\n",
    "\n",
    "X = features[:date]\n",
    "y = es_class[:date]\n",
    "\n",
    "# 5 fold time series split\n",
    "# The Validation is done like this:\n",
    "# TRAIN: [0] TEST: [1]\n",
    "# TRAIN: [0 1] TEST: [2]\n",
    "# TRAIN: [0 1 2] TEST: [3]\n",
    "# TRAIN: [0 1 2 3] TEST: [4]\n",
    "# TRAIN: [0 1 2 3 4] TEST: [5]\n",
    "\n",
    "tscv= TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "logloss = pd.DataFrame(index = range(6,21), columns=['rf', 'boost'])\n",
    "rocauc = pd.DataFrame(index = range(6,21), columns=['rf', 'boost'])\n",
    "\n",
    "for max_depth in range(6,21):\n",
    "    rf_logloss = []\n",
    "    boost_logloss = []\n",
    "    \n",
    "    rf_rocauc = []\n",
    "    boost_rocauc = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # Random Forest Classifier\n",
    "        clf = RandomForestClassifier(max_depth=max_depth, criterion='entropy', random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        rf_logloss.append(log_loss(clf.predict(X_test), y_test))\n",
    "        rf_rocauc.append(roc_auc_score(clf.predict(X_test), y_test))\n",
    "        # Gradient Boosting Classifier\n",
    "        clf = GradientBoostingClassifier(max_depth=max_depth, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        boost_logloss.append(log_loss(clf.predict(X_test), y_test))\n",
    "        boost_rocauc.append(roc_auc_score(clf.predict(X_test), y_test))\n",
    "        \n",
    "    logloss.loc[max_depth, 'rf'] = np.mean(rf_logloss)\n",
    "    logloss.loc[max_depth, 'boost'] = np.mean(boost_logloss)\n",
    "    \n",
    "            \n",
    "    rocauc.loc[max_depth, 'rf'] = np.mean(rf_rocauc)\n",
    "    rocauc.loc[max_depth, 'boost'] = np.mean(boost_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.4358</td>\n",
       "      <td>16.8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.4596</td>\n",
       "      <td>17.0075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.412</td>\n",
       "      <td>16.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.6978</td>\n",
       "      <td>16.3644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.5072</td>\n",
       "      <td>17.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.7931</td>\n",
       "      <td>16.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.5787</td>\n",
       "      <td>17.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.0789</td>\n",
       "      <td>17.2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.412</td>\n",
       "      <td>17.4363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.3882</td>\n",
       "      <td>17.1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.5787</td>\n",
       "      <td>17.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.4834</td>\n",
       "      <td>17.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.6978</td>\n",
       "      <td>17.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.7217</td>\n",
       "      <td>17.9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.5073</td>\n",
       "      <td>17.3887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rf    boost\n",
       "6   16.4358  16.8884\n",
       "7   16.4596  17.0075\n",
       "8    16.412  16.9837\n",
       "9   16.6978  16.3644\n",
       "10  16.5072  17.0552\n",
       "11  16.7931  16.9837\n",
       "12  16.5787  17.1266\n",
       "13  17.0789  17.2696\n",
       "14   16.412  17.4363\n",
       "15  16.3882  17.1743\n",
       "16  16.5787  17.1028\n",
       "17  16.4834  17.6983\n",
       "18  16.6978   17.079\n",
       "19  16.7217  17.9604\n",
       "20  16.5073  17.3887"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max reached at max_depth=15 for Random Forest, max_depth=9 for Boost\n",
    "logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.496931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.508627</td>\n",
       "      <td>0.492607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.501226</td>\n",
       "      <td>0.491009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.513954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.499638</td>\n",
       "      <td>0.490439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.48585</td>\n",
       "      <td>0.498611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500237</td>\n",
       "      <td>0.489983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.488558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.506507</td>\n",
       "      <td>0.48406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.510174</td>\n",
       "      <td>0.492034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.499757</td>\n",
       "      <td>0.49441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.50277</td>\n",
       "      <td>0.478198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.495435</td>\n",
       "      <td>0.496971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.499065</td>\n",
       "      <td>0.474763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.506748</td>\n",
       "      <td>0.491174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rf     boost\n",
       "6     0.5072  0.496931\n",
       "7   0.508627  0.492607\n",
       "8   0.501226  0.491009\n",
       "9     0.4941  0.513954\n",
       "10  0.499638  0.490439\n",
       "11   0.48585  0.498611\n",
       "12  0.500237  0.489983\n",
       "13  0.478843  0.488558\n",
       "14  0.506507   0.48406\n",
       "15  0.510174  0.492034\n",
       "16  0.499757   0.49441\n",
       "17   0.50277  0.478198\n",
       "18  0.495435  0.496971\n",
       "19  0.499065  0.474763\n",
       "20  0.506748  0.491174"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max reached at max_depth=15 for Random Forest, max_depth=9 for Boost\n",
    "rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(pos, ret):\n",
    "    # Mean of returns divided by standard deviation of returns, annualized\n",
    "    return np.sqrt(252) * ( pos * ret ).mean() / ( pos * ret ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two strategies: \n",
    "# One: If model predicts up move, buy S&P500 at close, if it predicts down move, flat\n",
    "# Two: If model predicts up move, buy S&P500 at close, if it predicts down move, short S&P500 at close\n",
    "\n",
    "# Sharpe for each fold for strategy One/Two\n",
    "rf_sharpe = []\n",
    "rf_short_sharpe = []\n",
    "\n",
    "boost_sharpe = []\n",
    "boost_short_sharpe = []\n",
    "\n",
    "# direction * return for each day for strategy One/Two\n",
    "rf_pos = []\n",
    "rf_pos_short = []\n",
    "\n",
    "boost_pos = []\n",
    "boost_pos_short = []\n",
    "\n",
    "# Up.down prediction for each day\n",
    "rf_position = []\n",
    "boost_position = []\n",
    "\n",
    "# Sharpe for SPX\n",
    "es_sharpe = []\n",
    "\n",
    "# Collecting stats for each training fold for the best model found\n",
    "\n",
    "X = features[:date]\n",
    "y = es_class[:date]\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    es_sharpe.append(sharpe_ratio(1,es['return'][test_index]))\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=15, criterion='entropy',random_state= 42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rf_sharpe.append(sharpe_ratio(clf.predict(X_test), es['return'][test_index]))\n",
    "    rf_short_sharpe.append(sharpe_ratio((2 * clf.predict(X_test) - 1), es['return'][test_index]))\n",
    "    rf_pos.append(clf.predict(X_test)*es['return'][test_index])\n",
    "    rf_position.append(clf.predict(X_test))\n",
    "    rf_pos_short.append((2 * clf.predict(X_test) - 1)*es['return'][test_index])\n",
    "    \n",
    "    clf = GradientBoostingClassifier(max_depth=9,random_state= 42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    boost_sharpe.append(sharpe_ratio(clf.predict(X_test), es['return'][test_index]))\n",
    "    boost_short_sharpe.append(sharpe_ratio((2 * clf.predict(X_test) - 1), es['return'][test_index]))\n",
    "    boost_pos.append(clf.predict(X_test)*es['return'][test_index])\n",
    "    boost_position.append(clf.predict(X_test))\n",
    "    boost_pos_short.append((2 * clf.predict(X_test) - 1)*es['return'][test_index])\n",
    "\n",
    "# Collecting stats for the test set for the best model found\n",
    "    \n",
    "X_train = features[:date]\n",
    "X_test = features[date:]\n",
    "\n",
    "y = 1*(es['return'] >0)\n",
    "\n",
    "y_train = y[:date]\n",
    "y_test = y[date:]\n",
    "\n",
    "es_sharpe.append(sharpe_ratio(1,es['return'][date:]))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=15, criterion='entropy',random_state= 42)\n",
    "clf.fit(X_train, y_train)\n",
    "rf_sharpe.append(sharpe_ratio(clf.predict(X_test), es['return'][date:]))\n",
    "rf_short_sharpe.append(sharpe_ratio((2 * clf.predict(X_test) - 1), es['return'][date:]))\n",
    "rf_pos.append(clf.predict(X_test)*es['return'][date:])\n",
    "rf_pos_short.append((2 * clf.predict(X_test) - 1)*es['return'][date:])\n",
    "rf_position.append(clf.predict(X_test))\n",
    "    \n",
    "clf = GradientBoostingClassifier(max_depth=9,random_state= 42)\n",
    "clf.fit(X_train, y_train)\n",
    "boost_sharpe.append(sharpe_ratio(clf.predict(X_test), es['return'][date:]))\n",
    "boost_short_sharpe.append(sharpe_ratio((2 * clf.predict(X_test) - 1), es['return'][date:]))\n",
    "boost_pos.append(clf.predict(X_test)*es['return'][date:])\n",
    "boost_pos_short.append((2 * clf.predict(X_test) - 1)*es['return'][date:])\n",
    "boost_position.append(clf.predict(X_test))\n",
    "\n",
    "\n",
    "rf_pos = pd.concat(rf_pos)\n",
    "rf_pos_short = pd.concat(rf_pos_short)\n",
    "rf_position = np.concatenate(rf_position)\n",
    "\n",
    "boost_pos = pd.concat(boost_pos)\n",
    "boost_pos_short = pd.concat(boost_pos_short)\n",
    "boost_position = np.concatenate(boost_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sharpe Long Total</th>\n",
       "      <th>Sharpe Short Total</th>\n",
       "      <th>Sharpe Long Test</th>\n",
       "      <th>Sharpe Short Test</th>\n",
       "      <th>Days Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPX</th>\n",
       "      <td>0.549085</td>\n",
       "      <td></td>\n",
       "      <td>0.69096</td>\n",
       "      <td>0.69096</td>\n",
       "      <td>0.629522</td>\n",
       "      <td>0.629522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.544648</td>\n",
       "      <td>0.646882</td>\n",
       "      <td>0.809364</td>\n",
       "      <td>0.707095</td>\n",
       "      <td>1.34748</td>\n",
       "      <td>1.62605</td>\n",
       "      <td>0.740433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradBoost</th>\n",
       "      <td>0.520244</td>\n",
       "      <td>0.600831</td>\n",
       "      <td>0.595086</td>\n",
       "      <td>0.254204</td>\n",
       "      <td>0.797615</td>\n",
       "      <td>0.561864</td>\n",
       "      <td>0.652801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy        F1 Sharpe Long Total Sharpe Short Total  \\\n",
       "SPX        0.549085                     0.69096            0.69096   \n",
       "RF         0.544648  0.646882          0.809364           0.707095   \n",
       "GradBoost  0.520244  0.600831          0.595086           0.254204   \n",
       "\n",
       "          Sharpe Long Test Sharpe Short Test Days Long  \n",
       "SPX               0.629522          0.629522         1  \n",
       "RF                 1.34748           1.62605  0.740433  \n",
       "GradBoost         0.797615          0.561864  0.652801  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats for both strategies\n",
    "# Strategy One is Long, Strategy Two is Short\n",
    "# Accuracy, F1-Score, Sharpe for full period, Sharpe for Test Set, % of days with a position\n",
    "\n",
    "Stats = pd.DataFrame(index=['SPX','RF','GradBoost'],\n",
    "            columns=['Accuracy', \n",
    "                     'F1', \n",
    "                     'Sharpe Long Total', \n",
    "                     'Sharpe Short Total', \n",
    "                     'Sharpe Long Test', \n",
    "                     'Sharpe Short Test', \n",
    "                     'Days Long'])\n",
    "\n",
    "fold_0_ind = 291\n",
    "\n",
    "Stats.loc['SPX','Accuracy'] = accuracy_score(y.iloc[fold_0_ind:]*0 + 1, y.iloc[fold_0_ind:])\n",
    "Stats.loc['RF', 'Accuracy'] = accuracy_score(rf_position, y.iloc[fold_0_ind:])\n",
    "Stats.loc['GradBoost', 'Accuracy'] = accuracy_score(boost_position, y.iloc[fold_0_ind:])\n",
    "\n",
    "Stats.loc['SPX','F1'] = ''\n",
    "Stats.loc['RF', 'F1'] = f1_score(rf_position, y.iloc[fold_0_ind:])\n",
    "Stats.loc['GradBoost', 'F1'] = f1_score(boost_position, y.iloc[fold_0_ind:])\n",
    "\n",
    "Stats.loc['SPX','Sharpe Long Total'] = sharpe_ratio(1,es.iloc[fold_0_ind:]['return'])\n",
    "Stats.loc['RF', 'Sharpe Long Total'] = sharpe_ratio(1,rf_pos)\n",
    "Stats.loc['GradBoost', 'Sharpe Long Total'] = sharpe_ratio(1,boost_pos)\n",
    "\n",
    "\n",
    "Stats.loc['SPX','Sharpe Short Total'] = sharpe_ratio(1,es.iloc[fold_0_ind:]['return'])\n",
    "Stats.loc['RF', 'Sharpe Short Total'] = sharpe_ratio(1,rf_pos_short)\n",
    "Stats.loc['GradBoost', 'Sharpe Short Total'] = sharpe_ratio(1,boost_pos_short)\n",
    "\n",
    "Stats.loc['SPX','Sharpe Long Test'] = es_sharpe[-1]\n",
    "Stats.loc['RF', 'Sharpe Long Test'] = rf_sharpe[-1]\n",
    "Stats.loc['GradBoost', 'Sharpe Long Test'] = boost_sharpe[-1]\n",
    "\n",
    "Stats.loc['SPX','Sharpe Short Test'] = es_sharpe[-1]\n",
    "Stats.loc['RF', 'Sharpe Short Test'] = rf_short_sharpe[-1]\n",
    "Stats.loc['GradBoost', 'Sharpe Short Test'] = boost_short_sharpe[-1]\n",
    "\n",
    "\n",
    "Stats.loc['SPX', 'Days Long'] = 1\n",
    "Stats.loc['RF', 'Days Long'] = rf_position.sum()/len(rf_position)\n",
    "Stats.loc['GradBoost', 'Days Long'] = boost_position.sum()/len(boost_position)\n",
    "\n",
    "Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest beats SPX and Gradboost in both the Long and Long/Short strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "date = '2018-12-31'\n",
    "\n",
    "X_train = features[:date]\n",
    "X_test = features[date:]\n",
    "\n",
    "y = 1*(es['return'] >0)\n",
    "\n",
    "y_train = y[:date]\n",
    "y_test = y[date:]\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=15, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "CCC = pd.DataFrame(columns=['feature_importances'], index = X_train.columns)\n",
    "CCC['feature_importances'] = clf.feature_importances_\n",
    "CCC.plot.barh(figsize=(10,5), legend=False, title=\"Feature Importance\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All features seem to contribute in a similar scale \n",
    "- Topic coherence seems the most important\n",
    "- Sentiment is split between different categories\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
