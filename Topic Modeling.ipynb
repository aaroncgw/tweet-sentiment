{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.tweet_data import read_raw_data\n",
    "from modules.topics import TopicSeries\n",
    "#from modules.tokens import spacy_twitter_model, twitter_tokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n"
     ]
    }
   ],
   "source": [
    "tweet_df = read_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-11 00:32:55</th>\n",
       "      <td>1281687871406186497</td>\n",
       "      <td>RANsquawk</td>\n",
       "      <td>Cheers good sir!!! you too mate :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-11 00:37:10</th>\n",
       "      <td>1281688941389905921</td>\n",
       "      <td>lindayueh</td>\n",
       "      <td>Prime Minister, who posed in a face covering f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-11 00:52:55</th>\n",
       "      <td>1281692904071876611</td>\n",
       "      <td>bopinion</td>\n",
       "      <td>Today, roughly 20% of all U.S.-listed stocks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-11 01:22:53</th>\n",
       "      <td>1281700446281838605</td>\n",
       "      <td>bopinion</td>\n",
       "      <td>We'll have to re-think some of our notions abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-11 01:53:32</th>\n",
       "      <td>1281708159606894598</td>\n",
       "      <td>bopinion</td>\n",
       "      <td>Something important is afoot.   Chinese stock ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                tweet_id     handle  \\\n",
       "timestamp                                             \n",
       "2020-07-11 00:32:55  1281687871406186497  RANsquawk   \n",
       "2020-07-11 00:37:10  1281688941389905921  lindayueh   \n",
       "2020-07-11 00:52:55  1281692904071876611   bopinion   \n",
       "2020-07-11 01:22:53  1281700446281838605   bopinion   \n",
       "2020-07-11 01:53:32  1281708159606894598   bopinion   \n",
       "\n",
       "                                                                 tweet  \n",
       "timestamp                                                               \n",
       "2020-07-11 00:32:55                 Cheers good sir!!! you too mate :)  \n",
       "2020-07-11 00:37:10  Prime Minister, who posed in a face covering f...  \n",
       "2020-07-11 00:52:55  Today, roughly 20% of all U.S.-listed stocks a...  \n",
       "2020-07-11 01:22:53  We'll have to re-think some of our notions abo...  \n",
       "2020-07-11 01:53:32  Something important is afoot.   Chinese stock ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df[tweet_df.index < '06-01-2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_day = tweet_df['2016-11-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy_twitter_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=lambda text: twitter_tokenizer(text, model=nlp))\n",
    "count_vecs = cv.fit_transform(single_day.tweet)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_vecs = lda.fit_transform(count_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda text: twitter_tokenizer(text, model=nlp))\n",
    "tfidf_vecs = tfidf.fit_transform(single_day.tweet)\n",
    "\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts =TopicSeries()\n",
    "ts.calculate_day('2016-11-09', tweet_df['2016-11-09'].tweet)\n",
    "ts.calculate_day('2016-05-08', tweet_df['2016-05-08'].tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LatentDirichletAllocation(n_components=5, random_state=42),\n",
       " CountVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7fc5ab2cb320>),\n",
       " NMF(n_components=5, random_state=5),\n",
       " TfidfVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7fc5ab2cb320>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.models['2016-11-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_components(model, word_features, top_display=5):\n",
    "    # utility for displaying respresentative words per component for topic models\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
    "        top_words = [word_features[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = [lda, cv, nmf, tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ts, open( \"save.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open( \"save.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LatentDirichletAllocation(n_components=5, random_state=42),\n",
       " CountVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7ffe7bc88440>),\n",
       " NMF(n_components=5, random_state=5),\n",
       " TfidfVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7ffe7bc88440>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.models['2016-11-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "day happy mother mothers mom moms love #mothersday great thank wife nice time celebrating appreciation important today life enjoy world\n",
      "Topic 1:\n",
      "trump donald says clinton hillary gop party women republican ryan going president win taxes paul nominee wealthy better candidate said\n",
      "Topic 2:\n",
      "lol yep seen look actual idiot irl pic pro true picks trying fireworks nails choice texas nice huh answer haha\n",
      "Topic 3:\n",
      "good luck morning point love story man pretty night new nt book true time years listen wo saudi change add\n",
      "Topic 4:\n",
      "like know thanks think people yes new look right sure going time saudi oh great actually minister china oil looks\n"
     ]
    }
   ],
   "source": [
    "display_components(a.models['2016-05-08'][2], a.models['2016-05-08'][3].get_feature_names(), top_display=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
