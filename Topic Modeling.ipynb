{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.tweet_data import read_raw_data\n",
    "from modules.topics import TopicSeries, display_components\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n"
     ]
    }
   ],
   "source": [
    "tweet_df = read_raw_data()\n",
    "es = pd.read_csv('data/ES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es[es.Time == '15:00'][['Date','Time','Close']]\n",
    "es.Date = pd.to_datetime(es.Date +' ' +'15:45')\n",
    "es.drop('Time',axis=1,inplace=True)\n",
    "es.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = es['2011-12-30':'2020-5-31'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = date_range[-100:]\n",
    "#date_range[-1200:-799]\n",
    "#batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-08\n",
      "2020-01-09\n",
      "2020-01-10\n",
      "2020-01-13\n",
      "2020-01-14\n",
      "2020-01-15\n",
      "2020-01-16\n",
      "2020-01-17\n",
      "2020-01-21\n",
      "2020-01-22\n",
      "2020-01-23\n",
      "2020-01-24\n",
      "2020-01-27\n",
      "2020-01-28\n",
      "2020-01-29\n",
      "2020-01-30\n",
      "2020-01-31\n",
      "2020-02-03\n",
      "2020-02-04\n",
      "2020-02-05\n",
      "2020-02-06\n",
      "2020-02-07\n",
      "2020-02-10\n",
      "2020-02-11\n",
      "2020-02-12\n",
      "2020-02-13\n",
      "2020-02-14\n",
      "2020-02-18\n",
      "2020-02-19\n",
      "2020-02-20\n",
      "2020-02-21\n",
      "2020-02-24\n",
      "2020-02-25\n",
      "2020-02-26\n",
      "2020-02-27\n",
      "2020-02-28\n",
      "2020-03-02\n",
      "2020-03-03\n",
      "2020-03-04\n",
      "2020-03-05\n",
      "2020-03-06\n",
      "2020-03-09\n",
      "2020-03-10\n",
      "2020-03-11\n",
      "2020-03-12\n",
      "2020-03-13\n",
      "2020-03-16\n",
      "2020-03-17\n",
      "2020-03-18\n",
      "2020-03-19\n",
      "2020-03-20\n",
      "2020-03-23\n",
      "2020-03-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\envs\\tweet-sentiment\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-25\n",
      "2020-03-26\n",
      "2020-03-27\n",
      "2020-03-30\n"
     ]
    }
   ],
   "source": [
    "ts=TopicSeries()\n",
    "for i in range(len(batch)-1):\n",
    "    str_date = str(batch[i+1].date())\n",
    "    print(str_date)\n",
    "    ts.calculate_nmf(str_date, \n",
    "                     tweet_df[batch[i]:(batch[i+1]-dt.timedelta(seconds=1))].tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump( ts, open( \"NMF-2018-10-19-2020-05-29.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df[tweet_df.index < '06-01-2020']\n",
    "single_day = tweet_df['2016-11-09']\n",
    "ts =TopicSeries()\n",
    "ts.calculate_day('2016-11-09', tweet_df['2016-11-09'].tweet)\n",
    "ts.calculate_day('2016-05-08', tweet_df['2016-05-08'].tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = [lda, cv, nmf, tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LatentDirichletAllocation(n_components=5, random_state=42),\n",
       " CountVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7ffe7bc88440>),\n",
       " NMF(n_components=5, random_state=5),\n",
       " TfidfVectorizer(tokenizer=<function TopicSeries.twitter_tokenizer at 0x7ffe7bc88440>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.models['2016-11-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "day happy mother mothers mom moms love #mothersday great thank wife nice time celebrating appreciation important today life enjoy world\n",
      "Topic 1:\n",
      "trump donald says clinton hillary gop party women republican ryan going president win taxes paul nominee wealthy better candidate said\n",
      "Topic 2:\n",
      "lol yep seen look actual idiot irl pic pro true picks trying fireworks nails choice texas nice huh answer haha\n",
      "Topic 3:\n",
      "good luck morning point love story man pretty night new nt book true time years listen wo saudi change add\n",
      "Topic 4:\n",
      "like know thanks think people yes new look right sure going time saudi oh great actually minister china oil looks\n"
     ]
    }
   ],
   "source": [
    "display_components(a.models['2016-05-08'][2], a.models['2016-05-08'][3].get_feature_names(), top_display=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
