{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from modules.tweet_data import read_raw_data\n",
    "from modules.spacy import spacy_twitter_model\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy_twitter_model()\n",
    "sentiment_model = pipeline('sentiment-analysis',device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n"
     ]
    }
   ],
   "source": [
    "tweet_df = read_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_tokenizer(data,\n",
    "                      model=nlp,\n",
    "                      urls=True,\n",
    "                      stop_words=False,\n",
    "                      lowercase=True,\n",
    "                      alpha_only=True,\n",
    "                      hashtags=True,\n",
    "                      lemma=False):\n",
    "    \"\"\"\n",
    "    Full tokenizer with flags for processing steps\n",
    "\n",
    "    Parameters:\n",
    "        data: string\n",
    "            String to be tokenized\n",
    "        model: Spacy model\n",
    "            Ideally, an output from the method spacy_twitter_model() from modules.spacy\n",
    "        urls: bool\n",
    "            If True, remove URLs and Twitter picture links\n",
    "        stop_words: bool\n",
    "            If True, removes stop words\n",
    "        lowercase: bool\n",
    "            If True, turns all tokens to lowercase\n",
    "        alpha_only: bool\n",
    "            If True, removes all non-alpha characters\n",
    "        hashtags: bool\n",
    "            If True, removes hashtags\n",
    "        lemma: bool\n",
    "            If True, lemmatizes words\n",
    "    \"\"\"\n",
    "    parsed = model(data)\n",
    "    # token collector\n",
    "    tokens = []\n",
    "    for t in parsed:\n",
    "        # remove URLs abd Twitter picture links\n",
    "        if t.like_url or t._.is_piclink & urls:\n",
    "            continue\n",
    "        # remove stopwords\n",
    "        if t.is_stop & stop_words:\n",
    "            continue\n",
    "        # alpha characters only\n",
    "        if not t.is_alpha & alpha_only:\n",
    "            # if not alpha only, remove hashtags\n",
    "            if hashtags:\n",
    "                continue\n",
    "            else:\n",
    "                if not t._.is_hashtag:\n",
    "                    continue\n",
    "        # lemmatize\n",
    "        if lemma:\n",
    "            t = t.lemma_\n",
    "        else:\n",
    "            t = t.text\n",
    "        # turn to lowercase\n",
    "        if lowercase:\n",
    "            t = t.lower()\n",
    "        tokens.append(t)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = tweet_df[['tweet_id']].copy()\n",
    "sentiment['sentiment'] = 0\n",
    "sentiment['score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540000/35109352, time 208.55\r"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for i in range(0,len(tweet_df),16):\n",
    "    if i%10000 == 0:\n",
    "        print(\"{}/{}, time {:.2f}\".format(i, len(tweet_df),(time.time() - t)/60),end=\"\\r\")\n",
    "    tokenized = [' '.join(twitter_tokenizer(tweet)) for tweet in tweet_df.tweet.iloc[i:i+16]]\n",
    "    sentiment_dict = sentiment_model(tokenized)\n",
    "    sentiment.sentiment.iloc[i:i+16] = [1 if d['label'] == 'POSITIVE' else -1 for d in sentiment_dict]\n",
    "    sentiment.score.iloc[i:i+16] = [d['score'] for d in sentiment_dict]\n",
    "    \n",
    "print(\"{}/{}, time {:.2f}\".format(i, len(tweet_df),(time.time() - t)/60),end=\"\\r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
